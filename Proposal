# Project Proposal

#### Group Members:
Euluna Gotami (ega48@sfu.ca)
John Aldrix Camino (jcamino@sfu.ca)
Sam McGarry (sma256@sfu.ca)
Stephanie Chen (yca497@sfu.ca)

### Project Idea
What problem is it solving?
The goal of our project is to develop an autonomous agent that is capable of navigating and defeating the dungeons in The Binding of Isaac. The agent should be able to address real-time combat, and also high-level strategic planning.

### What kind of input will it take, and what will it output?
The input of our system is the real-time game state data, which includes the agentâ€™s health, position, enemy positions, enemy types, rooms/maps, and items. The output of the system will be the real-time control actions (movement and combat) and navigational decisions.

### What AI techniques do you plan to use? (e.g., supervised learning, classification, search, planning, etc.)
To achieve the goal, we will implement a Reinforcement Learning (proximal proxy optimization) to handle combat movements (moving, dodging, attacking). An A* algorithm will be used to determine the most optimal path between rooms.

### Tools and Resources
Any external tools/libraries needed (e.g., scikit-learn, PyTorch, OpenCV)
We will be accessing the game through a modding API that exposes many game features via Lua. We will also most likely be using PyTorch to handle more complicated machine learning tasks in Lua. (https://wofsauge.github.io/IsaacDocs/rep/index.html)

### Will you generate your own dataset?
Our data will be entirely simulated, generated through multiple iterative gameplay sessions where the agent collects state-action-reward transitions during gameplay to optimize its actions in real-time.

### Will you use a simulator (e.g., PyBullet, OpenAI Gym) or work with real-world data?
We will treat The Binding of Isaac itself as the simulation environment and interface with it using the Lua Modding API.

### Project Plan / Timeline

### Milestone 1: early functionality (e.g., data preprocessing, basic model) (March 1)
Task 1: Turn Issac into an AI environment
Connect Lua to Python such that it sends state to and receives action from python.
Convert raw game data into tensor to make it easier for the RL model to process.

#### Task 2: Build Combat Model
Build a combat model so the agent can reliably clear one room. Start building the decision making model.
Define Markov Decision Process (MDP) including state, action and reward.
Train model in one room.
Evaluate room clear rate, damage taken and survival time, etc.

### Milestone 2: complete system with evaluation, visualization, and optional stretch features (March 29)
Task 3: Build Decision Model
Represent the floor as a graph with Nodes being rooms and edges being doors. Implement A* search to find the shortest path to the boss or a new room.
Add heuristics to find a safer room when HP is low. (optional?)

#### Task 4: Combine both Models
Complete decision making model and combine it with the combat model so the agent can clear all the rooms on the first floor.

##### Minimal viable product
Our MVP will be for the agent to successfully clear the first floor by using the reinforcement learning and decision-making model.
